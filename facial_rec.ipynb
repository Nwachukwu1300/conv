{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For quicker model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mmesoma/Desktop/FaceReg/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.15.1 in ./venv/lib/python3.9/site-packages (2.15.1)\n",
      "Requirement already satisfied: opencv-python in ./venv/lib/python3.9/site-packages (4.10.0.84)\n",
      "Requirement already satisfied: matplotlib in ./venv/lib/python3.9/site-packages (3.9.4)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in ./venv/lib/python3.9/site-packages (from tensorflow==2.15.1) (24.12.23)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in ./venv/lib/python3.9/site-packages (from tensorflow==2.15.1) (1.26.4)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in ./venv/lib/python3.9/site-packages (from tensorflow==2.15.1) (2.15.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./venv/lib/python3.9/site-packages (from tensorflow==2.15.1) (3.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./venv/lib/python3.9/site-packages (from tensorflow==2.15.1) (0.37.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in ./venv/lib/python3.9/site-packages (from tensorflow==2.15.1) (3.12.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./venv/lib/python3.9/site-packages (from tensorflow==2.15.1) (1.6.3)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./venv/lib/python3.9/site-packages (from tensorflow==2.15.1) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./venv/lib/python3.9/site-packages (from tensorflow==2.15.1) (0.2.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in ./venv/lib/python3.9/site-packages (from tensorflow==2.15.1) (1.14.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in ./venv/lib/python3.9/site-packages (from tensorflow==2.15.1) (4.25.5)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./venv/lib/python3.9/site-packages (from tensorflow==2.15.1) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./venv/lib/python3.9/site-packages (from tensorflow==2.15.1) (4.12.2)\n",
      "Requirement already satisfied: six>=1.12.0 in ./venv/lib/python3.9/site-packages (from tensorflow==2.15.1) (1.17.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in ./venv/lib/python3.9/site-packages (from tensorflow==2.15.1) (2.15.0)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.9/site-packages (from tensorflow==2.15.1) (58.0.4)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./venv/lib/python3.9/site-packages (from tensorflow==2.15.1) (1.68.1)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.9/site-packages (from tensorflow==2.15.1) (24.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./venv/lib/python3.9/site-packages (from tensorflow==2.15.1) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in ./venv/lib/python3.9/site-packages (from tensorflow==2.15.1) (0.3.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./venv/lib/python3.9/site-packages (from tensorflow==2.15.1) (2.1.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in ./venv/lib/python3.9/site-packages (from tensorflow==2.15.1) (2.15.2)\n",
      "Requirement already satisfied: pillow>=8 in ./venv/lib/python3.9/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.9/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./venv/lib/python3.9/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./venv/lib/python3.9/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.9/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in ./venv/lib/python3.9/site-packages (from matplotlib) (6.4.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./venv/lib/python3.9/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.9/site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./venv/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow==2.15.1) (0.45.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./venv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.21.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./venv/lib/python3.9/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.7)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in ./venv/lib/python3.9/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (1.2.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./venv/lib/python3.9/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.1.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./venv/lib/python3.9/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (0.7.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in ./venv/lib/python3.9/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2.37.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./venv/lib/python3.9/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2.32.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./venv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (0.4.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./venv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (5.5.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./venv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./venv/lib/python3.9/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in ./venv/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (8.5.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in ./venv/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2024.12.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2.3.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./venv/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./venv/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.0.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Users/mmesoma/Desktop/FaceReg/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow==2.15.1 opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import tensor flow dependencies - Functional API\n",
    "\n",
    "from tensorflow.keras.models import Model \n",
    "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten, BatchNormalization\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "#Model: Lets you build and train a neural network.\n",
    "#Layer: The base class for all Keras layers.\n",
    "#Conv2D: Adds convolutional layers to extract image features.\n",
    "#Dense: Fully connected layer for making decisions.\n",
    "#MaxPooling2D: Reduces image size while keeping key features.\n",
    "#Input: Defines the input shape of the model.\n",
    "#Flatten: Turns multi-dimensional data into a flat vector.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set GPU growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Avoiding out of memory errors for memory consumption\n",
    "gpus=tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "# Enable memory growth for each GPU, so TensorFlow uses memory as needed instead of pre-allocating all at once\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create folder structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting paths for directories\n",
    "\n",
    "POS_PATH = os.path.join('data', 'positive')\n",
    "NEG_PATH = os.path.join('data', 'negative')\n",
    "ANC_PATH = os.path.join('data', 'anchor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create directories\n",
    "\n",
    "#os.makedirs(POS_PATH)\n",
    "#os.makedirs(NEG_PATH)\n",
    "#os.makedirs(ANC_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving lfw pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##https://vis-www.cs.umass.edu/lfw/\n",
    "\n",
    "# Import required libraries\n",
    "import os\n",
    "\n",
    "# Uncompress the tgz dataset\n",
    "!tar -xf lfw.tgz\n",
    "\n",
    "# Ensure the negative path directory exists\n",
    "os.makedirs(NEG_PATH, exist_ok=True)\n",
    "\n",
    "# Move LFW images to the negative repository\n",
    "for directory in os.listdir('lfw'):\n",
    "    dir_path = os.path.join('lfw', directory)\n",
    "    if os.path.isdir(dir_path):  # Check if it's a directory\n",
    "        for file in os.listdir(dir_path):  # List files within the subdirectory\n",
    "            EX_PATH = os.path.join(dir_path, file)  # Current file path\n",
    "            NEW_PATH = os.path.join(NEG_PATH, file)  # New file path\n",
    "            os.replace(EX_PATH, NEW_PATH)  # Move the file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting anchor and positive images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 07:25:23.390 Python[41524:26282970] WARNING: Secure coding is automatically enabled for restorable state! However, not on all supported macOS versions of this application. Opt-in to secure coding explicitly by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState:.\n"
     ]
    }
   ],
   "source": [
    "#import uuid to generate unique image names\n",
    "import uuid\n",
    "\n",
    "#Establish connection to the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Define the crop ratio (e.g., 0.5 means 50% of the frame's size)\n",
    "    crop_ratio = 0.5\n",
    "\n",
    "    # Get the dimensions of the frame\n",
    "    height, width, _ = frame.shape\n",
    "\n",
    "    # Calculate the crop dimensions based on the ratio\n",
    "    crop_height = 250\n",
    "    crop_width = 250\n",
    "\n",
    "    # Calculate the center of the frame\n",
    "    center_y, center_x = height // 2, width // 2\n",
    "\n",
    "    # Define the coordinates for the crop here it'll be 250x250\n",
    "    start_y = max(0, center_y - crop_height // 2)\n",
    "    start_x = max(0, center_x - crop_width // 2)\n",
    "    end_y = start_y + crop_height\n",
    "    end_x = start_x + crop_width\n",
    "\n",
    "    frame = frame[start_y:end_y, start_x:end_x]\n",
    "\n",
    "    #Collect anchor \n",
    "    if cv2.waitKey(1) & 0XFF == ord('a'):\n",
    "        #Create unique file path\n",
    "        imgname=os.path.join(ANC_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
    "        #Write anchor image\n",
    "        cv2.imwrite(imgname,frame)\n",
    "\n",
    "    #Collect positives\n",
    "    if cv2.waitKey(1) & 0XFF == ord('p'):\n",
    "        #Create unique file path\n",
    "        imgname=os.path.join(POS_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
    "        #Write POSITIVE image\n",
    "        cv2.imwrite(imgname,frame)\n",
    "\n",
    "\n",
    "    #Show image back to screen \n",
    "    cv2.imshow('Image Collection', frame)\n",
    "\n",
    "    #breaking gracefully\n",
    "    if cv2.waitKey(1) & 0XFF == ord('q'):\n",
    "        break\n",
    "\n",
    "#release webcam\n",
    "cap.release()\n",
    "\n",
    "#close the image show frame\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#frame = frame[120:120+250, 200:200+250, :]  # Extract the image slice\n",
    "plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))  # Convert BGR to RGB\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting our imaage directories as datasets\n",
    "\n",
    "anchor=tf.data.Dataset.list_files(ANC_PATH+'/*.jpg').take(200)\n",
    "positive=tf.data.Dataset.list_files(POS_PATH+'/*.jpg').take(200)\n",
    "negative=tf.data.Dataset.list_files(NEG_PATH+'/*.jpg').take(200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_test = anchor.as_numpy_iterator() #testing the uuid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'data/anchor/84e36a9a-c2cf-11ef-a0d0-a63d57b1cd1f.jpg'\n"
     ]
    }
   ],
   "source": [
    "print(dir_test.next())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREPROCESS IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_path):\n",
    "    byte_img = tf.io.read_file(file_path)\n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    # Add basic image augmentation for better model generalization\n",
    "    img = tf.image.random_flip_left_right(img)  # Random horizontal flip\n",
    "    img = tf.image.random_brightness(img, 0.1)   # Slight brightness adjustment\n",
    "    img = tf.image.resize(img, (100, 100))\n",
    "    # Handle potential numerical instabilities\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=preprocess('data/anchor/8dd3a430-c2cf-11ef-a0d0-a63d57b1cd1f.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9267157"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.numpy().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17d2cedf0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives=tf.data.Dataset.zip((anchor,positive,tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
    "negatives=tf.data.Dataset.zip((anchor,negative,tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
    "\n",
    "# Combine both positive and negative pairs into a single dataset with a mix of matching and non-matching pairs\n",
    "data = positives.concatenate(negatives) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_ConcatenateDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data\n",
    "\n",
    "#The first string is our file path to the specific image, second string is the path to either the positive or neggative image\n",
    "#last value determines whether its +ve or -ve for verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "eg=sample.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BUILD, TRAIN AND TEST PARTITION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to preprcess the input and validation images as twins\n",
    "def preprocess_twins(input_img, validation_img, label):\n",
    "    try:\n",
    "        print(\"Input types:\", type(input_img), type(validation_img), type(label))\n",
    "        print(\"Input image values:\", input_img)\n",
    "        \n",
    "        def process_single_image(img):\n",
    "            # If the image is already a tensor, we need to handle it differently\n",
    "            if isinstance(img, tf.Tensor):\n",
    "                # If it's already a preprocessed image tensor\n",
    "                if img.dtype == tf.float32:\n",
    "                    return tf.image.resize(img,(100,100))\n",
    "                # If it's a string tensor (filepath)\n",
    "                elif img.dtype == tf.string:\n",
    "                    img = tf.io.read_file(img)\n",
    "                    img = tf.io.decode_jpeg(img, channels=3)\n",
    "                    img = tf.cast(img, tf.float32) / 255.0\n",
    "                    img = tf.image.resize(img, (100, 100))\n",
    "                    return img\n",
    "            return None\n",
    "        \n",
    "        processed_input = process_single_image(input_img)\n",
    "        processed_validation = process_single_image(validation_img)\n",
    "        \n",
    "        return processed_input, processed_validation, label\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing images: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample structure: [<class 'tensorflow.python.framework.ops.EagerTensor'>, <class 'tensorflow.python.framework.ops.EagerTensor'>, <class 'tensorflow.python.framework.ops.EagerTensor'>]\n",
      "First element shape/type: tf.Tensor([ 32 250 250   3], shape=(4,), dtype=int32) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# Check the first element of the dataset\n",
    "sample = next(iter(data))\n",
    "print(\"Sample structure:\", [type(x) for x in sample])\n",
    "print(\"First element shape/type:\", tf.shape(sample[0]), sample[0].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input types: <class 'bytes'> <class 'bytes'> <class 'numpy.float32'>\n",
      "Input image values: b'data/anchor/8b488a3c-c2cf-11ef-a0d0-a63d57b1cd1f.jpg'\n"
     ]
    }
   ],
   "source": [
    "res = preprocess_twins(*eg)  # * collecting the eg values from the register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build dataloader pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data_pipeline(data, batch_size=32):\n",
    "    # First, we'll make sure our images are all the right size (100x100)\n",
    "    data = data.map(preprocess_twins, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    # Cache is still good - keeps our preprocessed data in memory\n",
    "    data = data.cache()\n",
    "    \n",
    "    # Shuffle before batching to ensure good mixing\n",
    "    data = data.shuffle(1000)\n",
    "    \n",
    "    # Add drop_remainder=True to ensure all batches have the same size\n",
    "    data = data.batch(batch_size, drop_remainder=True)\n",
    "    \n",
    "    # Prefetch is still good for performance\n",
    "    data = data.prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input types: <class 'tensorflow.python.framework.ops.SymbolicTensor'> <class 'tensorflow.python.framework.ops.SymbolicTensor'> <class 'tensorflow.python.framework.ops.SymbolicTensor'>\n",
      "Input image values: Tensor(\"args_0:0\", shape=(None, None, None, 250, 250, 3), dtype=float32)\n",
      "Error processing images: 'images' must have either 3 or 4 dimensions.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/var/folders/l6/7n445dpj3bj189pnvn43qhrm0000gn/T/ipykernel_41524/1673661509.py\", line 12, in process_single_image  *\n        return tf.image.resize(img,(100,100))\n\n    ValueError: 'images' must have either 3 or 4 dimensions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create the training and validation datasets\u001b[39;00m\n\u001b[1;32m      2\u001b[0m BATCH_SIZE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[0;32m----> 3\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_data_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[89], line 3\u001b[0m, in \u001b[0;36mbuild_data_pipeline\u001b[0;34m(data, batch_size)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_data_pipeline\u001b[39m(data, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# First, we'll make sure our images are all the right size (100x100)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess_twins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAUTOTUNE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Cache is still good - keeps our preprocessed data in memory\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcache()\n",
      "File \u001b[0;32m~/Desktop/FaceReg/venv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:2280\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2276\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001b[39;00m\n\u001b[1;32m   2277\u001b[0m \u001b[38;5;66;03m# dataset_ops).\u001b[39;00m\n\u001b[1;32m   2278\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m   2279\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m map_op\n\u001b[0;32m-> 2280\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmap_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2281\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/FaceReg/venv/lib/python3.9/site-packages/tensorflow/python/data/ops/map_op.py:40\u001b[0m, in \u001b[0;36m_map_v2\u001b[0;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _MapDataset(\n\u001b[1;32m     38\u001b[0m       input_dataset, map_func, preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 40\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ParallelMapDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/FaceReg/venv/lib/python3.9/site-packages/tensorflow/python/data/ops/map_op.py:148\u001b[0m, in \u001b[0;36m_ParallelMapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_dataset \u001b[38;5;241m=\u001b[39m input_dataset\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism \u001b[38;5;241m=\u001b[39m use_inter_op_parallelism\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_legacy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_legacy_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deterministic \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/FaceReg/venv/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:265\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    259\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    260\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    261\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    262\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    263\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    267\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m~/Desktop/FaceReg/venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1227\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1226\u001b[0m   \u001b[38;5;66;03m# Implements PolymorphicFunction.get_concrete_function.\u001b[39;00m\n\u001b[0;32m-> 1227\u001b[0m   concrete \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1228\u001b[0m   concrete\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1229\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete\n",
      "File \u001b[0;32m~/Desktop/FaceReg/venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1197\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1196\u001b[0m     initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1197\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m   1201\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m   1202\u001b[0m   \u001b[38;5;66;03m# version which is guaranteed to never create variables.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/FaceReg/venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:695\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[1;32m    691\u001b[0m     variable_capturing_scope,\n\u001b[1;32m    692\u001b[0m     tracing_compilation\u001b[38;5;241m.\u001b[39mScopeType\u001b[38;5;241m.\u001b[39mVARIABLE_CREATION,\n\u001b[1;32m    693\u001b[0m )\n\u001b[1;32m    694\u001b[0m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[0;32m--> 695\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    700\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/FaceReg/venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/FaceReg/venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[0;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[1;32m    290\u001b[0m   )\n",
      "File \u001b[0;32m~/Desktop/FaceReg/venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    303\u001b[0m   placeholder_bound_args \u001b[38;5;241m=\u001b[39m function_type\u001b[38;5;241m.\u001b[39mplaceholder_arguments(\n\u001b[1;32m    304\u001b[0m       placeholder_context\n\u001b[1;32m    305\u001b[0m   )\n\u001b[1;32m    307\u001b[0m disable_acd \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39mattributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mattributes\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    308\u001b[0m     attributes_lib\u001b[38;5;241m.\u001b[39mDISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    309\u001b[0m )\n\u001b[0;32m--> 310\u001b[0m traced_func_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction_type_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m transform\u001b[38;5;241m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[1;32m    324\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m traced_func_graph\u001b[38;5;241m.\u001b[39mfunction_captures\n",
      "File \u001b[0;32m~/Desktop/FaceReg/venv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1059\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1056\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m   1058\u001b[0m _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1059\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m~/Desktop/FaceReg/venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:598\u001b[0m, in \u001b[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    595\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    596\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 598\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    599\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/Desktop/FaceReg/venv/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:231\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[0;32m--> 231\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mwrapper_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m   ret \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_structure, ret)\n\u001b[1;32m    233\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n",
      "File \u001b[0;32m~/Desktop/FaceReg/venv/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:161\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[1;32m    160\u001b[0m   nested_args \u001b[38;5;241m=\u001b[39m (nested_args,)\n\u001b[0;32m--> 161\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_ctx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnested_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m ret \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(ret)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n",
      "File \u001b[0;32m~/Desktop/FaceReg/venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:693\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m    694\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    695\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/FaceReg/venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 690\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/Desktop/FaceReg/venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/var/folders/l6/7n445dpj3bj189pnvn43qhrm0000gn/T/__autograph_generated_filei_u8cixz.py:101\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__preprocess_twins\u001b[0;34m(input_img, validation_img, label)\u001b[0m\n\u001b[1;32m     99\u001b[0m         ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mnot_(do_return_1), if_body_3, else_body_3, get_state_3, set_state_3, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdo_return_1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretval__1\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fscope_1\u001b[38;5;241m.\u001b[39mret(retval__1, do_return_1)\n\u001b[0;32m--> 101\u001b[0m processed_input \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_single_image\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_img\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m processed_validation \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(process_single_image), (ag__\u001b[38;5;241m.\u001b[39mld(validation_img),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/FaceReg/venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:339\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_autograph_artifact(f):\n\u001b[1;32m    338\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPermanently allowed: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: AutoGraph artifact\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n\u001b[0;32m--> 339\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;66;03m# If this is a partial, unwrap it and redo all the checks.\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, functools\u001b[38;5;241m.\u001b[39mpartial):\n",
      "File \u001b[0;32m~/Desktop/FaceReg/venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:460\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/var/folders/l6/7n445dpj3bj189pnvn43qhrm0000gn/T/__autograph_generated_filei_u8cixz.py:78\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__preprocess_twins.<locals>.process_single_image\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mnonlocal\u001b[39;00m do_return_1, retval__1, img\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mif_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope_1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_body_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melse_body_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdo_return_1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mretval__1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state_3\u001b[39m():\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (do_return_1, retval__1)\n",
      "File \u001b[0;32m~/Desktop/FaceReg/venv/lib/python3.9/site-packages/tensorflow/python/autograph/operators/control_flow.py:1217\u001b[0m, in \u001b[0;36mif_stmt\u001b[0;34m(cond, body, orelse, get_state, set_state, symbol_names, nouts)\u001b[0m\n\u001b[1;32m   1215\u001b[0m   _tf_if_stmt(cond, body, orelse, get_state, set_state, symbol_names, nouts)\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1217\u001b[0m   \u001b[43m_py_if_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morelse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/FaceReg/venv/lib/python3.9/site-packages/tensorflow/python/autograph/operators/control_flow.py:1270\u001b[0m, in \u001b[0;36m_py_if_stmt\u001b[0;34m(cond, body, orelse)\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_py_if_stmt\u001b[39m(cond, body, orelse):\n\u001b[1;32m   1269\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Overload of if_stmt that executes a Python if statement.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1270\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbody\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m cond \u001b[38;5;28;01melse\u001b[39;00m orelse()\n",
      "File \u001b[0;32m/var/folders/l6/7n445dpj3bj189pnvn43qhrm0000gn/T/__autograph_generated_filei_u8cixz.py:73\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__preprocess_twins.<locals>.process_single_image.<locals>.if_body_2\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mld(img)\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mstring, if_body, else_body, get_state, set_state, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdo_return_1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretval__1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 73\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mif_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_body_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melse_body_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdo_return_1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mretval__1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/FaceReg/venv/lib/python3.9/site-packages/tensorflow/python/autograph/operators/control_flow.py:1217\u001b[0m, in \u001b[0;36mif_stmt\u001b[0;34m(cond, body, orelse, get_state, set_state, symbol_names, nouts)\u001b[0m\n\u001b[1;32m   1215\u001b[0m   _tf_if_stmt(cond, body, orelse, get_state, set_state, symbol_names, nouts)\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1217\u001b[0m   \u001b[43m_py_if_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morelse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/FaceReg/venv/lib/python3.9/site-packages/tensorflow/python/autograph/operators/control_flow.py:1270\u001b[0m, in \u001b[0;36m_py_if_stmt\u001b[0;34m(cond, body, orelse)\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_py_if_stmt\u001b[39m(cond, body, orelse):\n\u001b[1;32m   1269\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Overload of if_stmt that executes a Python if statement.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1270\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbody\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m cond \u001b[38;5;28;01melse\u001b[39;00m orelse()\n",
      "File \u001b[0;32m/var/folders/l6/7n445dpj3bj189pnvn43qhrm0000gn/T/__autograph_generated_filei_u8cixz.py:41\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__preprocess_twins.<locals>.process_single_image.<locals>.if_body_2.<locals>.if_body_1\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m     do_return_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m     retval__1 \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope_1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m     do_return_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/FaceReg/venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[1;32m    330\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: from cache\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n\u001b[0;32m--> 331\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx()\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m ag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED:\n\u001b[1;32m    334\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: AutoGraph is disabled in context\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n",
      "File \u001b[0;32m~/Desktop/FaceReg/venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:460\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/FaceReg/venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Desktop/FaceReg/venv/lib/python3.9/site-packages/tensorflow/python/ops/image_ops_impl.py:1467\u001b[0m, in \u001b[0;36m_resize_images_common\u001b[0;34m(images, resizer_fn, size, preserve_aspect_ratio, name, skip_resize_if_same)\u001b[0m\n\u001b[1;32m   1465\u001b[0m   images \u001b[38;5;241m=\u001b[39m array_ops\u001b[38;5;241m.\u001b[39mexpand_dims(images, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   1466\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m images\u001b[38;5;241m.\u001b[39mget_shape()\u001b[38;5;241m.\u001b[39mndims \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m-> 1467\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m must have either 3 or 4 dimensions.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1469\u001b[0m _, height, width, _ \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mget_shape()\u001b[38;5;241m.\u001b[39mas_list()\n\u001b[1;32m   1471\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/var/folders/l6/7n445dpj3bj189pnvn43qhrm0000gn/T/ipykernel_41524/1673661509.py\", line 12, in process_single_image  *\n        return tf.image.resize(img,(100,100))\n\n    ValueError: 'images' must have either 3 or 4 dimensions.\n"
     ]
    }
   ],
   "source": [
    "# Create the training and validation datasets\n",
    "BATCH_SIZE = 32\n",
    "data = build_data_pipeline(data, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(len(data)*0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = round(len(data) * 0.7)    # Calculates split point\n",
    "train_data = data.take(train_size)     # Takes 70% of data\n",
    "val_data = data.skip(train_size)      # Creates test set from remaining 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug function to check dataset shapes\n",
    "def inspect_dataset(dataset, name=\"Dataset\"):\n",
    "    print(f\"\\nInspecting {name}:\")\n",
    "    try:\n",
    "        for batch_idx, batch in enumerate(dataset.take(1)):\n",
    "            print(f\"Batch {batch_idx + 1}:\")\n",
    "            print(f\"Input shape: {batch[0].shape}\")\n",
    "            print(f\"Validation shape: {batch[1].shape}\")\n",
    "            print(f\"Label shape: {batch[2].shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error while inspecting dataset: {str(e)}\")\n",
    "        print(\"Dataset element spec:\", dataset.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inspecting Training Data:\n",
      "\n",
      "Inspecting Testing Data:\n"
     ]
    }
   ],
   "source": [
    "# Check both datasets\n",
    "inspect_dataset(train_data, \"Training Data\")\n",
    "inspect_dataset(val_data, \"Testing Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec=(TensorSpec(shape=(None, None, None, 250, 250, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, None, None, 250, 250, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, None, None), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample = train_data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample =train_sample.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sample[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing partition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data.skip(round(len(data)*0.7))\n",
    "test_data = test_data.take(round(len(data)*0.3))\n",
    "test_data = test_data.batch(16) \n",
    "test_data = test_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf  Siememse networks paper\n",
    "\n",
    "#Builds embedding layer\n",
    "\n",
    "def make_embedding():\n",
    "    inp=Input(shape=(100,100,3), name='input_image')\n",
    "\n",
    "    #First block \n",
    "    c1 = Conv2D(64, (10,10), activation='relu')(inp)\n",
    "    c1 = BatchNormalization()(c1)\n",
    "    m1 = MaxPooling2D(64,(2,2),padding='same')(c1)\n",
    "\n",
    "    #Second block\n",
    "    c2 = Conv2D(128, (3,3), activation='relu')(m1)\n",
    "    m2 = MaxPooling2D(64,(2,2),padding='same')(c2)\n",
    "\n",
    "    #Third block \n",
    "    c3 = Conv2D(128, (7,7), activation='relu')(m2)\n",
    "    m3 = MaxPooling2D(64,(2,2),padding='same')(c3)\n",
    "\n",
    "    #Fouth block\n",
    "    c4 = Conv2D(256, (4,4), activation='relu')(m3)\n",
    "    f1 = Flatten()(c4)\n",
    "    d1 = Dense(4096, activation='sigmoid')(f1)\n",
    "\n",
    "\n",
    "    return Model(inputs=[inp], outputs=[d1], name='embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = make_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"embedding\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_image (InputLayer)    [(None, 100, 100, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 91, 91, 64)        19264     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 91, 91, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 46, 46, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 44, 44, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 22, 22, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 16, 16, 128)       802944    \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 8, 8, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 5, 5, 256)         524544    \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 6400)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4096)              26218496  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27639360 (105.44 MB)\n",
      "Trainable params: 27639232 (105.44 MB)\n",
      "Non-trainable params: 128 (512.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build distance layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class L1Dist(Layer):\n",
    "\n",
    "    #Init method for inheritance\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "    #Des the similarity calculation \n",
    "    def call(self, input_embedding, validation_embedding):\n",
    "        return tf.math.abs(input_embedding - validation_embedding) + 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = L1Dist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Siamese model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_siamese_model():\n",
    "    # Anchor image input in the network\n",
    "    input_image = Input(name='input_img', shape=(100,100,3))\n",
    "\n",
    "    #Validation image in the network\n",
    "    validation_image = Input(name='validation_img', shape=(100,100,3))\n",
    "\n",
    "    #Combine siamese distance components\n",
    "    siamise_layer = L1Dist()\n",
    "    siamise_layer._name = 'distance'\n",
    "    distances = siamise_layer(embedding(input_image), embedding(validation_image))\n",
    "\n",
    "    #Classification layer\n",
    "    classifier = Dense(1, activation='sigmoid')(distances)\n",
    "\n",
    "    return Model(inputs=[input_image, validation_image], outputs=classifier, name='SiameseNetwork')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model = make_siamese_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"SiameseNetwork\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_img (InputLayer)      [(None, 100, 100, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " validation_img (InputLayer  [(None, 100, 100, 3)]        0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " embedding (Functional)      (None, 4096)                 2763936   ['input_img[0][0]',           \n",
      "                                                          0          'validation_img[0][0]']      \n",
      "                                                                                                  \n",
      " distance (L1Dist)           (None, 4096)                 0         ['embedding[0][0]',           \n",
      "                                                                     'embedding[1][0]']           \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 1)                    4097      ['distance[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 27643457 (105.45 MB)\n",
      "Trainable params: 27643329 (105.45 MB)\n",
      "Non-trainable params: 128 (512.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAINING OUR MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = tf.losses.BinaryCrossentropy()\n",
    "\n",
    "initial_learning_rate = 1e-4\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.legacy.Adam(learning_rate=lr_schedule) #learning rate @ 0.0001 initially then gradually reduces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a ckeckpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(opt=opt, siamese_model=siamese_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build train step function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = train_data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch1 = test_batch.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1.,\n",
       "        1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0.],\n",
       "       [0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.],\n",
       "       [0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
       "        0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1.],\n",
       "       [0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
       "        1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1.],\n",
       "       [1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
       "        1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1.],\n",
       "       [1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
       "        1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0.],\n",
       "       [0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.],\n",
       "       [0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1.,\n",
       "        0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0.,\n",
       "        0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1.]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch1[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(batch):\n",
    "    \n",
    "    #Record all of our operations\n",
    "    with tf.GradientTape() as tape:\n",
    "        #get anchor and positive or negative\n",
    "        X=batch[:2]\n",
    "\n",
    "        #get label\n",
    "        Y=batch[2]\n",
    "\n",
    "        #frward pass\n",
    "        yhat = siamese_model(X, training= True)\n",
    "\n",
    "        #calculate loss\n",
    "        loss= loss_function(Y, yhat)\n",
    "    print(loss)\n",
    "\n",
    "    #calculate gradient\n",
    "    gradient = tape.gradient(loss, siamese_model.trainable_variables)\n",
    "    # Clip gradients to prevent exploding gradients\n",
    "    clipped_gradients = [tf.clip_by_value(g, -1.0, 1.0) for g in gradient]\n",
    "    # calculate updated weights and apply to siamese model\n",
    "    opt.apply_gradients(zip(clipped_gradients, siamese_model.trainable_variables))\n",
    "\n",
    "\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, EPOCHS):\n",
    "    #loop through epochs\n",
    "    for epoch in range(1,EPOCHS+1): \n",
    "        print('\\n Epoch{}/{}'.format(epoch, EPOCHS)) #prints 1 out of number of epochs\n",
    "        progbar = tf.keras.utils.Progbar(len(data)) #progress bar, if i wrapped this up in a model class no need but i want more control\n",
    "\n",
    "        # Keep track of losses for each epoch\n",
    "        epoch_loss = tf.keras.metrics.Mean()\n",
    "\n",
    "        #loop through each batch\n",
    "        for idx, batch in enumerate(data):\n",
    "            loss = train_step(batch)  # Make sure train_step returns a scalar loss value\n",
    "            epoch_loss.update_state(loss)\n",
    "            progbar.update(idx+1, values=[('loss', epoch_loss.result())])\n",
    "\n",
    "        #save checkpoints\n",
    "        if epoch % 10 ==0:\n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_3_device_/job:localhost/replica:0/task:0/device:CPU:0}} Cannot batch tensors with different shapes in component 0. First element had shape [32,250,250,3] and element 8 had shape [16,250,250,3]. [Op:IteratorGetNext] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Check data shape\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_data\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/Desktop/FaceReg/venv/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:810\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    809\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 810\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    811\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/FaceReg/venv/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:773\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[0;32m--> 773\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    778\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/FaceReg/venv/lib/python3.9/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3029\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3027\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3028\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 3029\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3030\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[1;32m   3031\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/FaceReg/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:5883\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5881\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   5882\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 5883\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_3_device_/job:localhost/replica:0/task:0/device:CPU:0}} Cannot batch tensors with different shapes in component 0. First element had shape [32,250,250,3] and element 8 had shape [16,250,250,3]. [Op:IteratorGetNext] name: "
     ]
    }
   ],
   "source": [
    "# Check data shape\n",
    "for batch in train_data.take(1):\n",
    "    print(\"Input shape:\", batch[0].shape)\n",
    "    print(\"Validation shape:\", batch[1].shape)\n",
    "    print(\"Label shape:\", batch[2].shape)\n",
    "    break\n",
    "\n",
    "# Check model input shape\n",
    "print(\"\\nModel input shape:\")\n",
    "for layer in siamese_model.layers:\n",
    "    if isinstance(layer, tf.keras.layers.InputLayer):\n",
    "        print(f\"{layer.name}: {layer.input_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch1/50\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_3_device_/job:localhost/replica:0/task:0/device:CPU:0}} Cannot batch tensors with different shapes in component 0. First element had shape [32,250,250,3] and element 7 had shape [16,250,250,3]. [Op:IteratorGetNext] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m siamese_model \u001b[38;5;241m=\u001b[39m make_siamese_model()  \u001b[38;5;66;03m# Your model creation function\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Train with the new improvements\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[61], line 11\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(data, EPOCHS)\u001b[0m\n\u001b[1;32m      8\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mMean()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#loop through each batch\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data):\n\u001b[1;32m     12\u001b[0m     loss \u001b[38;5;241m=\u001b[39m train_step(batch)  \u001b[38;5;66;03m# Make sure train_step returns a scalar loss value\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     epoch_loss\u001b[38;5;241m.\u001b[39mupdate_state(loss)\n",
      "File \u001b[0;32m~/Desktop/FaceReg/venv/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:810\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    809\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 810\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    811\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/FaceReg/venv/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:773\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[0;32m--> 773\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    778\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/FaceReg/venv/lib/python3.9/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3029\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3027\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3028\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 3029\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3030\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[1;32m   3031\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/FaceReg/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:5883\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5881\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   5882\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 5883\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_3_device_/job:localhost/replica:0/task:0/device:CPU:0}} Cannot batch tensors with different shapes in component 0. First element had shape [32,250,250,3] and element 7 had shape [16,250,250,3]. [Op:IteratorGetNext] name: "
     ]
    }
   ],
   "source": [
    "# Clear any existing weights and start fresh\n",
    "siamese_model = make_siamese_model()  # Your model creation function\n",
    "# Train with the new improvements\n",
    "train(train_data, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EVALUATE MODEL"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
