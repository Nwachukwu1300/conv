{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For quicker model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow==2.15.1 opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import tensor flow dependencies - Functional API\n",
    "\n",
    "from tensorflow.keras.models import Model \n",
    "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten, BatchNormalization\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "#Model: Lets you build and train a neural network.\n",
    "#Layer: The base class for all Keras layers.\n",
    "#Conv2D: Adds convolutional layers to extract image features.\n",
    "#Dense: Fully connected layer for making decisions.\n",
    "#MaxPooling2D: Reduces image size while keeping key features.\n",
    "#Input: Defines the input shape of the model.\n",
    "#Flatten: Turns multi-dimensional data into a flat vector.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set GPU growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Avoiding out of memory errors for memory consumption\n",
    "gpus=tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "# Enable memory growth for each GPU, so TensorFlow uses memory as needed instead of pre-allocating all at once\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create folder structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting paths for directories\n",
    "\n",
    "POS_PATH = os.path.join('data', 'positive')\n",
    "NEG_PATH = os.path.join('data', 'negative')\n",
    "ANC_PATH = os.path.join('data', 'anchor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Look for Bush photos in the negative directory\n",
    "bush_images = [img for img in os.listdir(NEG_PATH) if img.startswith('George_W_Bush')]\n",
    "print(f\"Found {len(bush_images)} Bush images\")\n",
    "\n",
    "# Shuffle the images for random split\n",
    "random.shuffle(bush_images)\n",
    "\n",
    "# Split point - half for anchor, half for positive\n",
    "split = len(bush_images) // 2\n",
    "\n",
    "# Move (not copy) to anchor and positive directories\n",
    "for i, img in enumerate(bush_images):\n",
    "    source_path = os.path.join(NEG_PATH, img)\n",
    "    if i < split:\n",
    "        destination_path = os.path.join(ANC_PATH, img)\n",
    "    else:\n",
    "        destination_path = os.path.join(POS_PATH, img)\n",
    "    # Move the file (removes it from negatives)\n",
    "    shutil.move(source_path, destination_path)\n",
    "\n",
    "print(f\"Moved {split} images to anchor directory\")\n",
    "print(f\"Moved {len(bush_images) - split} images to positive directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting our imaage directories as datasets\n",
    "\n",
    "anchor=tf.data.Dataset.list_files(ANC_PATH+'/*.jpg').take(200)\n",
    "positive=tf.data.Dataset.list_files(POS_PATH+'/*.jpg').take(200)\n",
    "negative=tf.data.Dataset.list_files(NEG_PATH+'/*.jpg').take(200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify how we create training pairs to ensure equal positive/negative examples\n",
    "positive_samples = min(len(list(anchor)), len(list(positive)))\n",
    "negative_samples = positive_samples\n",
    "anchor = anchor.take(positive_samples)\n",
    "positive = positive.take(positive_samples)\n",
    "negative = negative.take(negative_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREPROCESS IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_path):\n",
    "    byte_img = tf.io.read_file(file_path)\n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    # Add basic image augmentation for better model generalization\n",
    "    img = tf.image.random_flip_left_right(img)  # Random horizontal flip\n",
    "    img = tf.image.random_brightness(img, 0.2)   # Slight brightness adjustment\n",
    "    img = tf.image.random_contrast(img, lower=0.8, upper=1.2)\n",
    "    img = tf.image.resize(img, (100, 100))\n",
    "    # Handle potential numerical instabilities\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives=tf.data.Dataset.zip((anchor,positive,tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
    "negatives=tf.data.Dataset.zip((anchor,negative,tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
    "\n",
    "# Combine both positive and negative pairs into a single dataset with a mix of matching and non-matching pairs\n",
    "raw_data = positives.concatenate(negatives) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate split sizes\n",
    "total_size = len(raw_data)\n",
    "train_size = round(total_size * 0.7)\n",
    "val_size = total_size - train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data\n",
    "\n",
    "#The first string is our file path to the specific image, second string is the path to either the positive or neggative image\n",
    "#last value determines whether its +ve or -ve for verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=raw_data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "eg=sample.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BUILD, TRAIN AND TEST PARTITION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to preprcess the input and validation images as twins\n",
    "def preprocess_twins(input_img, validation_img, label):\n",
    "    try:\n",
    "        print(\"Input types:\", type(input_img), type(validation_img), type(label))\n",
    "        print(\"Input image values:\", input_img)\n",
    "        \n",
    "        def process_single_image(img):\n",
    "            # If the image is already a tensor, we need to handle it differently\n",
    "            if isinstance(img, tf.Tensor):\n",
    "                # If it's already a preprocessed image tensor\n",
    "                if img.dtype == tf.float32:\n",
    "                    return tf.image.resize(img,(100,100))\n",
    "                # If it's a string tensor (filepath)\n",
    "                elif img.dtype == tf.string:\n",
    "                    img = tf.io.read_file(img)\n",
    "                    img = tf.io.decode_jpeg(img, channels=3)\n",
    "                    img = tf.cast(img, tf.float32) / 255.0\n",
    "                    img = tf.image.resize(img, (100, 100))\n",
    "                    return img\n",
    "            return None\n",
    "        \n",
    "        processed_input = process_single_image(input_img)\n",
    "        processed_validation = process_single_image(validation_img)\n",
    "        \n",
    "        return processed_input, processed_validation, label\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing images: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the first element of the dataset\n",
    "sample = next(iter(raw_data))\n",
    "print(\"Sample structure:\", [type(x) for x in sample])\n",
    "print(\"First element shape/type:\", tf.shape(sample[0]), sample[0].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = preprocess_twins(*eg)  # * collecting the eg values from the register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build dataloader pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data_pipeline(data, batch_size=32, training=True):\n",
    "    \"\"\"\n",
    "    Creates an optimized data pipeline that properly handles caching.\n",
    "    The order of operations is crucial for efficient data processing.\n",
    "    \"\"\"\n",
    "    # First preprocess the raw images\n",
    "    data = data.map(preprocess_twins, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    if training:\n",
    "        # For training data, shuffle before batching\n",
    "        data = data.shuffle(1000)\n",
    "    \n",
    "    # Batch the data\n",
    "    data = data.batch(batch_size, drop_remainder=True)\n",
    "    \n",
    "    # Cache after batching to store complete batches\n",
    "    data = data.cache()\n",
    "    \n",
    "    # Prefetch at the end for pipeline efficiency\n",
    "    data = data.prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the shapes\n",
    "def verify_shapes(dataset, name):\n",
    "    print(f\"\\nVerifying {name} shapes:\")\n",
    "    for batch in dataset.take(1):\n",
    "        print(f\"Input shape: {batch[0].shape}\")\n",
    "        print(f\"Validation shape: {batch[1].shape}\")\n",
    "        print(f\"Label shape: {batch[2].shape}\")\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and verify datasets with monitoring\n",
    "def create_and_verify_datasets(raw_data, batch_size=32):\n",
    "    # Calculate split sizes\n",
    "    total_size = len(raw_data)\n",
    "    train_size = round(total_size * 0.7)\n",
    "    \n",
    "    # Split raw data\n",
    "    raw_train = raw_data.take(train_size)\n",
    "    raw_val = raw_data.skip(train_size)\n",
    "    \n",
    "    # Create pipelines\n",
    "    train_data = build_data_pipeline(raw_train, batch_size, training=True)\n",
    "    val_data = build_data_pipeline(raw_val, batch_size, training=False)\n",
    "    \n",
    "    # Verify both datasets\n",
    "    print(\"\\nDataset Statistics:\")\n",
    "    print(f\"Total examples: {total_size}\")\n",
    "    print(f\"Training examples: {train_size}\")\n",
    "    print(f\"Validation examples: {total_size - train_size}\")\n",
    "    \n",
    "    return train_data, val_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check both datasets\n",
    "verify_shapes(train_data, \"Training Data\")\n",
    "verify_shapes(val_data, \"Validation Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the improved creation function\n",
    "train_data, val_data = create_and_verify_datasets(raw_data, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample = train_data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample =train_sample.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_sample[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf  Siememse networks paper\n",
    "\n",
    "#Builds embedding layer\n",
    "\n",
    "def make_embedding():\n",
    "    inp=Input(shape=(100,100,3), name='input_image')\n",
    "\n",
    "    #First block \n",
    "    c1 = Conv2D(64, (10,10), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(inp)\n",
    "    c1 = BatchNormalization()(c1)\n",
    "    m1 = MaxPooling2D(64,(2,2),padding='same')(c1)\n",
    "    m1 = tf.keras.layers.Dropout(0.3)(m1)\n",
    "\n",
    "    #Second block\n",
    "    c2 = Conv2D(128, (3,3), activation='relu')(m1)\n",
    "    m2 = MaxPooling2D(64,(2,2),padding='same')(c2)\n",
    "    m2 = tf.keras.layers.Dropout(0.3)(m2)\n",
    "\n",
    "    #Third block \n",
    "    c3 = Conv2D(128, (7,7), activation='relu')(m2)\n",
    "    m3 = MaxPooling2D(64,(2,2),padding='same')(c3)\n",
    "    m3 = tf.keras.layers.Dropout(0.3)(m3)\n",
    "\n",
    "    #Fouth block\n",
    "    c4 = Conv2D(256, (4,4), activation='relu')(m3)\n",
    "    f1 = Flatten()(c4)\n",
    "    d1 = Dense(4096, activation='sigmoid')(f1)\n",
    "\n",
    "\n",
    "    return Model(inputs=[inp], outputs=[d1], name='embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = make_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build distance layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "class L1Dist(Layer):\n",
    "\n",
    "    #Init method for inheritance\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "    #Des the similarity calculation \n",
    "    def call(self, input_embedding, validation_embedding):\n",
    "        return tf.math.abs(input_embedding - validation_embedding) + 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = L1Dist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Siamese model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_siamese_model():\n",
    "    # Anchor image input in the network\n",
    "    input_image = Input(name='input_img', shape=(100,100,3))\n",
    "\n",
    "    #Validation image in the network\n",
    "    validation_image = Input(name='validation_img', shape=(100,100,3))\n",
    "\n",
    "    #Combine siamese distance components\n",
    "    siamise_layer = L1Dist()\n",
    "    siamise_layer._name = 'distance'\n",
    "    distances = siamise_layer(embedding(input_image), embedding(validation_image))\n",
    "\n",
    "    #Classification layer\n",
    "    classifier = Dense(1, activation='sigmoid')(distances)\n",
    "\n",
    "    return Model(inputs=[input_image, validation_image], outputs=classifier, name='SiameseNetwork')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model = make_siamese_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAINING OUR MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = tf.losses.BinaryCrossentropy()\n",
    "\n",
    "initial_learning_rate = 1e-5\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=500,\n",
    "    decay_rate=0.95\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.legacy.Adam(learning_rate=lr_schedule) #learning rate @ 0.0001 initially then gradually reduces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a ckeckpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(opt=opt, siamese_model=siamese_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add before training\n",
    "import shutil\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    shutil.rmtree(checkpoint_dir)\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build train step function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = train_data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch1 = test_batch.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch1[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(batch):\n",
    "    # Get anchor and positive/negative images\n",
    "    X = batch[:2]\n",
    "    # Get label\n",
    "    Y = batch[2]\n",
    "    \n",
    "    # Record operations with gradient tape\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Forward pass through the model\n",
    "        yhat = siamese_model(X, training=True)\n",
    "        # Calculate loss\n",
    "        loss = loss_function(Y, yhat)\n",
    "    \n",
    "    # Calculate gradients\n",
    "    gradients = tape.gradient(loss, siamese_model.trainable_variables)\n",
    "    # Clip gradients to prevent exploding gradients\n",
    "    clipped_gradients = [tf.clip_by_value(g, -1.0, 1.0) for g in gradients]\n",
    "    # Apply gradients to update model\n",
    "    opt.apply_gradients(zip(clipped_gradients, siamese_model.trainable_variables))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, EPOCHS):\n",
    "    for epoch in range(1, EPOCHS+1): \n",
    "        print(f'\\nEpoch {epoch}/{EPOCHS}')\n",
    "        progbar = tf.keras.utils.Progbar(len(data))\n",
    "        \n",
    "        # Track losses for this epoch\n",
    "        epoch_loss = tf.keras.metrics.Mean()\n",
    "        \n",
    "        for idx, batch in enumerate(data):\n",
    "            # Get numerical loss value\n",
    "            loss = train_step(batch)\n",
    "            epoch_loss.update_state(loss)\n",
    "            \n",
    "            # Update progress bar with actual loss value\n",
    "            progbar.update(\n",
    "                idx+1, \n",
    "                values=[('loss', float(epoch_loss.result()))]\n",
    "            )\n",
    "            \n",
    "        # Save checkpoints every 10 epochs\n",
    "        if epoch % 10 == 0:\n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data shape\n",
    "for batch in train_data.take(1):\n",
    "    print(\"Input shape:\", batch[0].shape)\n",
    "    print(\"Validation shape:\", batch[1].shape)\n",
    "    print(\"Label shape:\", batch[2].shape)\n",
    "    break\n",
    "\n",
    "# Check model input shape\n",
    "print(\"\\nModel input shape:\")\n",
    "for layer in siamese_model.layers:\n",
    "    if isinstance(layer, tf.keras.layers.InputLayer):\n",
    "        print(f\"{layer.name}: {layer.input_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model by running one batch through it\n",
    "for batch in train_data.take(1):\n",
    "    X = batch[:2]\n",
    "    # Do a forward pass to initialize variables\n",
    "    _ = siamese_model(X, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(train_data, EPOCHS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EVALUATE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_data, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Enhanced evaluation with raw prediction analysis\n",
    "    \"\"\"\n",
    "    test_loss = tf.metrics.Mean()\n",
    "    raw_predictions = []\n",
    "    raw_labels = []\n",
    "    \n",
    "    for batch in test_data:\n",
    "        X = batch[:2]\n",
    "        y_true = batch[2]\n",
    "        y_pred = model(X, training=False)\n",
    "        \n",
    "        # Store raw values for analysis\n",
    "        raw_predictions.extend(y_pred.numpy().flatten())\n",
    "        raw_labels.extend(y_true.numpy().flatten())\n",
    "        \n",
    "        test_loss.update_state(loss_function(y_true, y_pred))\n",
    "    \n",
    "    # Convert to numpy arrays for easier analysis\n",
    "    predictions = np.array(raw_predictions)\n",
    "    labels = np.array(raw_labels)\n",
    "    \n",
    "    # Print prediction distribution\n",
    "    print(f\"\\nPrediction Statistics:\")\n",
    "    print(f\"Min prediction: {predictions.min():.4f}\")\n",
    "    print(f\"Max prediction: {predictions.max():.4f}\")\n",
    "    print(f\"Mean prediction: {predictions.mean():.4f}\")\n",
    "    \n",
    "    # Calculate metrics using numpy\n",
    "    y_pred_binary = (predictions > threshold).astype(float)\n",
    "    \n",
    "    tp = np.sum((labels == 1) & (y_pred_binary == 1))\n",
    "    fp = np.sum((labels == 0) & (y_pred_binary == 1))\n",
    "    tn = np.sum((labels == 0) & (y_pred_binary == 0))\n",
    "    fn = np.sum((labels == 1) & (y_pred_binary == 0))\n",
    "    \n",
    "    accuracy = (tp + tn) / len(labels) if len(labels) > 0 else 0\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'loss': float(test_loss.result()),\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1_score,\n",
    "        'true_positives': int(tp),\n",
    "        'false_positives': int(fp),\n",
    "        'true_negatives': int(tn),\n",
    "        'false_negatives': int(fn),\n",
    "        'threshold_used': threshold,\n",
    "        'prediction_mean': float(predictions.mean()),\n",
    "        'prediction_std': float(predictions.std())\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_evaluation():\n",
    "    \"\"\"\n",
    "    Tests the model evaluation function and displays results in a readable format.\n",
    "    \"\"\"\n",
    "    # Load the model\n",
    "    siamese_model = make_siamese_model()\n",
    "    \n",
    "    # Restore the latest checkpoint\n",
    "    checkpoint = tf.train.Checkpoint(siamese_model=siamese_model)\n",
    "    latest_checkpoint = tf.train.latest_checkpoint('./training_checkpoints')\n",
    "    \n",
    "    if latest_checkpoint:\n",
    "        print(\"Loading model from checkpoint...\")\n",
    "        checkpoint.restore(latest_checkpoint)\n",
    "        print(\"Model restored successfully!\")\n",
    "    else:\n",
    "        print(\"No checkpoint found. Using untrained model.\")\n",
    "    \n",
    "    # Create a fresh validation dataset for each threshold\n",
    "    thresholds = [0.3, 0.5, 0.7]\n",
    "    for threshold in thresholds:\n",
    "        print(f\"\\nEvaluating model with threshold {threshold}:\")\n",
    "        # Recreate validation data for each threshold evaluation\n",
    "        _, fresh_val_data = create_and_verify_datasets(raw_data, BATCH_SIZE)\n",
    "        results = evaluate_model(siamese_model, fresh_val_data, threshold)\n",
    "        \n",
    "        # Display results in a readable format\n",
    "        print(\"\\nEvaluation Metrics:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"Loss: {results['loss']:.4f}\")\n",
    "        print(f\"Accuracy: {results['accuracy']:.4f} ({results['accuracy']*100:.1f}%)\")\n",
    "        print(f\"Precision: {results['precision']:.4f} ({results['precision']*100:.1f}%)\")\n",
    "        print(f\"Recall: {results['recall']:.4f} ({results['recall']*100:.1f}%)\")\n",
    "        print(f\"F1 Score: {results['f1_score']:.4f}\")\n",
    "        \n",
    "        print(\"\\nConfusion Matrix:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"True Positives: {results['true_positives']}\")\n",
    "        print(f\"False Positives: {results['false_positives']}\")\n",
    "        print(f\"True Negatives: {results['true_negatives']}\")\n",
    "        print(f\"False Negatives: {results['false_negatives']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_model_predictions(model, test_data):\n",
    "    \"\"\"\n",
    "    Detailed inspection of model predictions\n",
    "    \"\"\"\n",
    "    # Get single batch\n",
    "    for batch in test_data.take(1):\n",
    "        X = batch[:2]\n",
    "        y_true = batch[2]\n",
    "        y_pred = model(X, training=False)\n",
    "        \n",
    "        print(\"Label distribution:\", np.unique(y_true, return_counts=True))\n",
    "        print(\"Prediction range:\", np.min(y_pred), \"-\", np.max(y_pred))\n",
    "        \n",
    "        # Look at embeddings\n",
    "        embedding_layer = model.get_layer('embedding')\n",
    "        embeddings = embedding_layer(X[0])\n",
    "        print(\"Embedding stats:\", {\n",
    "            'mean': np.mean(embeddings),\n",
    "            'std': np.std(embeddings),\n",
    "            'min': np.min(embeddings),\n",
    "            'max': np.max(embeddings)\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detailed_model_inspection(model, test_data):\n",
    "    \"\"\"\n",
    "    Detailed model inspection with image pair analysis\n",
    "    \"\"\"\n",
    "    for batch in test_data.take(1):\n",
    "        X = batch[:2]\n",
    "        y_true = batch[2]\n",
    "        \n",
    "        # Get embeddings for both images\n",
    "        embedding_layer = model.get_layer('embedding')\n",
    "        embeddings1 = embedding_layer(X[0])\n",
    "        embeddings2 = embedding_layer(X[1])\n",
    "        \n",
    "        # Compare embeddings\n",
    "        distances = tf.abs(embeddings1 - embeddings2)\n",
    "        \n",
    "        print(\"\\nEmbedding Analysis:\")\n",
    "        print(f\"First image embeddings range: {tf.reduce_min(embeddings1):.4f} to {tf.reduce_max(embeddings1):.4f}\")\n",
    "        print(f\"Second image embeddings range: {tf.reduce_min(embeddings2):.4f} to {tf.reduce_max(embeddings2):.4f}\")\n",
    "        print(f\"Distance range: {tf.reduce_min(distances):.4f} to {tf.reduce_max(distances):.4f}\")\n",
    "        print(f\"Average distance: {tf.reduce_mean(distances):.4f}\")\n",
    "        \n",
    "        # Get model predictions\n",
    "        predictions = model([X[0], X[1]], training=False)\n",
    "        \n",
    "        # Print paired results\n",
    "        for i in range(min(5, len(y_true))):  # Show first 5 pairs\n",
    "            print(f\"\\nPair {i+1}:\")\n",
    "            print(f\"True label: {y_true[i]}\")\n",
    "            print(f\"Prediction: {predictions[i][0]:.4f}\")\n",
    "            print(f\"Average embedding distance: {tf.reduce_mean(distances[i]):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_model_inspection(siamese_model, val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_model_predictions(siamese_model, val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the evaluation test\n",
    "test_model_evaluation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
